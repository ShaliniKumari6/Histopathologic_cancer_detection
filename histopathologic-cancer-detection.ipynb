{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\nimport cv2\nimport keras\nimport keras.backend as K\nfrom sklearn.svm import SVC\nfrom sklearn.utils import shuffle\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\nfrom keras import layers\nfrom keras.models import Model,load_model\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras import optimizers\nfrom tensorflow.keras import callbacks\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom keras import regularizers,initializers\nfrom sklearn.metrics import classification_report, confusion_matrix, average_precision_score\nfrom sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, cohen_kappa_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\ndf=df.head(160000)\ndf=shuffle(df)\ninput_Examples=10000 #traindf.shape[0]\ninputExamples=50\nprint(\"No.of training images: \",df.shape[0],\"Columns: \",df.shape[1])\nprint(df.columns)\nprint(df.head(20))\nfilenames,labels=df['id'],df['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"XTRN = np.zeros(shape=(input_Examples,96,96,3))\nfor i in range(input_Examples):\n    fname= r'../input/histopathologic-cancer-detection/train/'+ filenames[i] + '.tif'\n    img = cv2.imread(fname)\n    img = cv2.resize(img, (96,96), interpolation = cv2.INTER_AREA)\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    XTRN[i] = img\n\nheight=XTRN.shape[1]\nwidth=XTRN.shape[2]\ndepth=XTRN.shape[3]\ninput_shape = (height, width, depth)\nchanDim = -1\n# if we are using \"channels first\", update the input shape and channels dimension\nif K.image_data_format() == \"channels_first\":\n    input_shape = (depth, height, width)\n    chanDim = 1\nprint(\"Total Train Images:\",XTRN.shape[0],\"Width:\",width,\"Height\",height,\"Channels:\",depth)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"number of training examples = \" + str(XTRN.shape[0]))\nprint (\"XTRN shape: \" + str(XTRN.shape))\nprint (\"YTRN shape: \" + str(YTRN.shape))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Train, X_Test, Y_Train, Y_Test = train_test_split(XTRN,YTRN, test_size = 0.10,shuffle=True, random_state = 7)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbl_present=np.unique(labels)\nnumclasses=len(lbl_present)\nclasses=dict(labels.value_counts())\nclass_df=pd.DataFrame({\"classname\":list(classes.keys()),\"No.of examples\":list(classes.values())})\n\nclass_df.plot(kind='bar', label='Class Name', color=[[ 'purple','LIMEGREEN']])\nplt.title('Number of images for different label type')\nplt.xlabel('label')\nplt.ylabel('Counts')\nplt.grid(axis='y')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generator","metadata":{}},{"cell_type":"code","source":"def getDataGen(model_name,input_shape):\n    height,width,channels = input_shape\n    preprocess_func = None\n    def zscoreNorm(x):\n        return (x - x.mean()) / x.std()  if x.std() > 0 else x\n    def minmax(x):\n        return x/255.0\n        \n    if model_name=='vgg16':\n        preprocess_func = minmax\n    if model_name=='pretrain_vgg16':\n        preprocess_func = keras.applications.vgg16.preprocess_input\n    if model_name=='pretrain_ResNet50':\n        preprocess_func = keras.applications.resnet.preprocess_input\n    if model_name=='pretrain_InceptionV3':\n        preprocess_func = keras.applications.inception_v3.preprocess_input\n    if model_name=='pretrain_DenseNet121':\n        preprocess_func = keras.applications.densenet.preprocess_input\n    if model_name=='pretrain_MobileNet':\n        preprocess_func = keras.applications.mobilenet.preprocess_input\n    if model_name=='HCD-CNN':\n        preprocess_func = minmax\n\n    datagenTrain = ImageDataGenerator(\n                        featurewise_center=False,\n                        samplewise_center=False,\n                        featurewise_std_normalization=False,\n                        samplewise_std_normalization=False,\n                        #rotation_range=90,\n                        #width_shift_range=0.2,#[-200,200] \n                        #height_shift_range=0.2, \n                        #brightness_range = [0.5,1.0],\n                        #shear_range=0.1,\n                        #zoom_range = [0.8,0.8], # Lower value more zoom!!\n                        horizontal_flip=True,  \n                        vertical_flip=True,\n                        #fill_mode='nearest',\n                        preprocessing_function=preprocess_func\n                )\n    datagenTest = ImageDataGenerator(\n                        #horizontal_flip=True,  \n                        #vertical_flip=True,\n                        #rescale=1.0/255\n                        preprocessing_function=preprocess_func\n                )\n    print(preprocess_func)\n    return datagenTrain, datagenTest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train,Test,val split  // using flow_from_directory()","metadata":{}},{"cell_type":"code","source":"try:\n    os.mkdir('img_dir')\nexcept FileExistsError:\n    pass\nimg_dir=os.path.join('../input/output/','img_dir')\ndfData=shuffle(pd.concat([filenames,labels],axis=1).reset_index(drop=True))\ny=dfData['label']\ndfTrain,dfTest = train_test_split(dfData, test_size = 0.10,shuffle=True, random_state = 7,stratify=y)\ny=dfTrain['label']\ndf_train,df_val = train_test_split(dfTrain, test_size = 0.10,shuffle=True, random_state = 7,stratify=y)\ntrainPath='img_dir/train'\nvalPath='img_dir/val'\ntestPath='img_dir/test'\nfor root_dir in [trainPath,valPath,testPath]:\n    for subf in ['0','1']:\n        try:\n            os.makedirs(os.path.join(root_dir, subf))\n        except FileExistsError:\n            pass\nclassCountsTrain=pd.DataFrame(np.array(np.unique(df_train['label'], return_counts=True)).T, columns=['Class','Freq']).set_index('Class')\nclassCountsTrain['Freq'] = classCountsTrain['Freq'] / np.sum(classCountsTrain['Freq'])\n\n#print(classCountsTrain)\nclassCountsTrain.plot(kind='bar',label='Class',color=[['purple','LIMEGREEN']])\nplt.title('Class Proportion in Training:')\nplt.xlabel('label')\nplt.ylabel('Counts')\nplt.grid(axis='y')\n\nclassCountsVal=pd.DataFrame(np.array(np.unique(df_val['label'], return_counts=True)).T, columns=['Class','Freq']).set_index('Class')\nclassCountsVal['Freq'] = classCountsVal['Freq'] / np.sum(classCountsVal['Freq'])\n#print(classCountsVal)\nclassCountsVal.plot(kind='bar', label='Class', color=[[ 'purple', 'LIMEGREEN']])\nplt.title('Class Proportion in Validation:')\nplt.xlabel('label')\nplt.ylabel('Counts')\nplt.grid(axis='y')\ndfData\nweight = compute_class_weight('balanced', np.unique(df_train['label']), df_train['label'])\nweights = {i : weight[i] for i in range(2)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"src_path='../input/histopathologic-cancer-detection/train'\n\nfor i in range(len(df_train)):\n    fname=df_train.iloc[i,0] + '.tif'\n    label=df_train.iloc[i,1]\n    src = os.path.join(src_path, fname)\n    dst = os.path.join(trainPath, str(label), fname)\n    shutil.copyfile(src, dst)\n\nfor i in range(len(df_val)):\n    fname=df_val.iloc[i,0] + '.tif'\n    label=df_val.iloc[i,1]\n    src = os.path.join(src_path, fname)\n    dst = os.path.join(valPath, str(label), fname)\n    shutil.copyfile(src, dst)\n\nfor i in range(len(dfTest)):\n    fname=dfTest.iloc[i,0] + '.tif'\n    label=dfTest.iloc[i,1]\n    src = os.path.join(src_path, fname)\n    dst = os.path.join(testPath,str(label), fname)\n    shutil.copyfile(src, dst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"height=96\nwidth=96\ndepth=3\ninput_shape = (height, width, depth)\nchanDim = -1\n# if we are using \"channels first\", update the input shape and channels dimension\nif K.image_data_format() == \"channels_first\":\n    input_shape = (depth, height, width)\n    chanDim = 1\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\nnum_test_samples = len(dfTest)\nprint(\"Total Train Images:\",num_train_samples,\"Width:\",width,\"Height\",height,\"Channels:\",depth)\nprint(\"Total Validation Images:\",num_val_samples,\"Width:\",width,\"Height\",height,\"Channels:\",depth)\nprint(\"Total Test Images:\",num_test_samples,\"Width:\",width,\"Height\",height,\"Channels:\",depth)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def getOptimizer(optimizer_name='Adam',lr=0.01):\n    if optimizer_name=='Adam':\n        optimizer = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-12, decay=1e-6, amsgrad=False)\n    elif optimizer_name=='SGD':\n        optimizer=optimizers.SGD(lr=lr, decay=1e-6, momentum=0.0, nesterov=False)\n    elif optimizer_name=='SGD_Momentum':\n        optimizer=optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=False)\n    elif optimizer_name=='SGD_Nesterov':\n        optimizer=optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n    elif optimizer_name=='RMSprop':\n        optimizer=optimizers.RMSprop(lr=lr, rho=0.9, epsilon=1e-12, decay=0.0)\n    elif optimizer_name=='Adagrad':\n        optimizer=optimizers.Adagrad(lr=lr, epsilon=None, decay=0.0)\n    elif optimizer_name=='Adadelta':\n        optimizer=optimizers.Adadelta(lr=lr, rho=0.95, epsilon=None, decay=0.0)\n    elif optimizer_name=='Adamax':\n        optimizer=optimizers.Adamax(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n    elif optimizer_name=='Nadam':\n        optimizer=optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004) #Nesterov Adam optimizer\n    return optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate_reduction = callbacks.ReduceLROnPlateau(  monitor='val_loss', \n                                                                    patience=10, \n                                                                    verbose=1, \n                                                                    factor=0.5,\n                                                                    min_lr=0.00001,\n                                                                    min_delta=1e-4, \n                                                                    mode='min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = callbacks.EarlyStopping(monitor='val_loss', \n                                         min_delta=1e-6, \n                                         patience=100, \n                                         verbose=1, \n                                         mode='min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=32\nepochs = 50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_History(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].grid(True, axis='both')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n    axs[0].legend(['Train','Validation'], loc='upper left')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].grid(True, axis='both')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['Train','Validation'], loc='upper left')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model_name,model,optimizer,numclasses,X_Train,Y_Train,chanDim=-1,batch_size=32,epochs=10):\n    class_counts=pd.DataFrame(np.array(np.unique(Y_Train,return_counts=True)).T,columns=['class','frequency'])\n    class_counts['frequency']=class_counts['frequency']/np.sum(class_counts['frequency'])\n    print(\"Class Proportion in Train Set\")\n    print(class_counts)\n    checkpoint_saving = callbacks.ModelCheckpoint(filepath=\"../input/output/weight_dir/chkPnt\"+model_name+\".h5\",\n                                              save_weights_only=True,\n                                              monitor='val_acc', \n                                              save_best_only=True,  \n                                              mode='max')\n    if model_name='pretrain_InceptionV3':\n        X_Train=keras.applications.inception_v3.preprocess_input(X_Train)\n    if model_name='pretrain_MobileNet': \n        X_Train=keras.applications.mobilenet.preprocess_input(X_Train)\n        \n    X_train, X_val, Y_train, Y_val = train_test_split(X_Train,Y_Train, test_size = 0.10,shuffle=True, random_state = 7)\n    print(\"Train and validation size :\",X_train.shape,X_val.shape,Y_train.shape,Y_val.shape)\n    class_counts=pd.DataFrame(np.array(np.unique(Y_train,return_counts=True)).T,columns=['class','frequency'])\n    class_counts['frequency']=class_counts['frequency']/np.sum(class_counts['frequency'])\n    print(\"Class Proportion in Training:\")\n    print(class_counts)\n    Y_train=to_categorical(Y_train,num_classes=numclasses,dtype='float64')\n    Y_val=to_categorical(Y_val,num_classes=numclasses,dtype='float64')\n    model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n   \n\n    datagenTrain, datagenTest = getDataGen(model_name,input_shape)\n    augmented_train_data=datagenTrain.flow(X_train,Y_train,batch_size=batch_size,\n                                     shuffle=True)\n    augmented_val_data=datagenTest.flow(X_val,Y_val,batch_size=batch_size,\n                                     shuffle=False)\n                                    \n    history_Training=model.fit_generator(augmented_train_data,\n                                         steps_per_epoch=np.ceil(X_train.shape[0]//batch_size),\n                                         epochs=epochs,\n                                         verbose=1,\n                                         validation_data=augmented_val_data,\n                                         validation_steps=np.ceil(X_val.shape[0]//batch_size),\n                                         class_weight=weight,\n                                         callbacks=[checkpoint_saving,learning_rate_reduction])\n    plot_History(history_Training)\n    print('------------------------------------------------------------------------')\n    print('Mean Validation Score: Loss of',np.mean(history_Training.history['val_loss']), 'Mean Accuracy of:', np.mean(history_Training.history['val_accuracy'])*100)\n    print('------------------------------------------------------------------------')\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model_ffd(model_name,model,optimizer_name,lr,numclasses,chanDim=-1,batch_size=32,epochs=10,compile_model=True):\n    weights_Path=model_name+'.h5'\n    heigh,width,channel=input_shape\n    datagenTrain, datagenTest = getDataGen(model_name,input_shape)\n    \n    train_gen = datagenTrain.flow_from_directory(trainPath,\n                                                target_size=(height,width),\n                                                batch_size=batch_size,\n                                                shuffle=True,\n                                                interpolation='lanczos',\n                                                class_mode='categorical')\n    val_gen = datagenTest.flow_from_directory(valPath,\n                                                target_size=(height,width),\n                                                batch_size=batch_size,\n                                                shuffle=True,\n                                                interpolation='lanczos',\n                                                class_mode='categorical')\n   \n        \n    optimizer= getOptimizer(optimizer_name,lr)\n    if compile_model==True:\n        model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n   \n    checkpoint_saving = callbacks.ModelCheckpoint(filepath=\"chkPnt\"+model_name+\".h5\",\n                                              save_weights_only=True,\n                                              monitor='val_accuracy', \n                                              save_best_only=True,  \n                                              mode='max')\n   \n    history_Training=model.fit_generator(train_gen,\n                                         steps_per_epoch=np.ceil(num_train_samples/batch_size),\n                                         epochs=epochs,\n                                         verbose=1,\n                                         validation_data=val_gen,\n                                         validation_steps=np.ceil(num_val_samples/batch_size),\n                                         class_weight=weights,\n                                         callbacks=[early_stopping,checkpoint_saving,learning_rate_reduction])\n    model.save(weights_Path,include_optimizer=True)\n    plot_History(history_Training)\n    print('available metrics',model.metrics_names)\n    print('------------------------------------------------------------------------')\n    print('Mean Validation Score: Loss of',np.mean(history_Training.history['val_loss']), 'Mean Accuracy of:', np.mean(history_Training.history['val_accuracy'])*100)\n    print('------------------------------------------------------------------------')\n\n    return model\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grid search","metadata":{}},{"cell_type":"code","source":"optimizer_name=['Adam','SGD_Momentum','SGD_Nesterov']\nlr=np.power(10,np.arange(-3,-1,dtype=float))\nneuron=[512,1024]\ndropRate=[0.1,0.2,0.3,0.4,0.5]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gridSearch_ffd(model_name,numclasses,paramGrid,chanDim=-1,batch_size=32,epochs=10):\n    if paramGrid!=None and len(paramGrid)>0:\n        heigh,width,channel=input_shape\n        datagenTrain, datagenTest = getDataGen(model_name,input_shape)\n        train_gen = datagenTrain.flow_from_directory(trainPath,\n                                                        target_size=(height,width),\n                                                        batch_size=batch_size,\n                                                        shuffle=True,\n                                                        interpolation='lanczos',\n                                                        class_mode='categorical')\n        val_gen = datagenTest.flow_from_directory(valPath,\n                                                    target_size=(height,width),\n                                                    batch_size=batch_size,\n                                                    shuffle=True,\n                                                    interpolation='lanczos',\n                                                    class_mode='categorical')\n        best_param={'model_name':model_name,'optimizer':None,'lr':0,'neuron':0,'dropRate':0,'acc_score':0}\n        for optimizer_name,lr,neuron,dropRate in paramGrid:\n            optimizer= getOptimizer(optimizer_name,lr)\n            if model_name=='vgg16': \n                model=vgg16scratch(numclasses,input_shape,chanDim,'he_normal',neuron,dropRate)\n            if model_name=='pretrain_vgg16': \n                model=vgg16_pretrained(numclasses,input_shape,chanDim,'he_normal',neuron,dropRate)\n            if model_name=='pretrain_InceptionV3':\n                model=inceptionv3_pretrained(numclasses,input_shape,chanDim,'he_normal',neuron,dropRate)\n            if model_name=='pretrain_MobileNet': \n                model=mobilenet_pretrained(numclasses,input_shape,chanDim,'he_normal',neuron,dropRate)\n            if model_name=='pretrain_ResNet50':\n                model=resnet50_pretrained(numclasses,input_shape,chanDim,'he_normal',neuron,dropRate)\n            if model_name=='pretrain_DenseNet121':\n                model=densenet121_pretrained(numclasses,input_shape,chanDim,'he_normal',neuron,dropRate)\n            if model_name=='HCD-CNN':\n                model=testNet(numclasses,input_shape,chanDim,'he_normal',neuron,dropRate)\n\n            model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n\n            history_Training=model.fit_generator(train_gen,\n                                                 steps_per_epoch=np.ceil(num_train_samples/batch_size),\n                                                 epochs=epochs,\n                                                 verbose=0,\n                                                 validation_data=val_gen,\n                                                 validation_steps=np.ceil(num_val_samples/batch_size),\n                                                 class_weight=weights)   \n            val_acc=np.mean(history_Training.history['val_accuracy'])*100\n            val_loss=np.mean(history_Training.history['val_loss'])\n            if val_acc>best_param['acc_score']:\n                best_param['optimizer']=optimizer_name\n                best_param['lr']=lr\n                best_param['neuron']=neuron\n                best_param['dropRate']=dropRate\n                best_param['acc_score']=val_acc\n            print('hyperparameters for the model',model_name,'with optimizer =',optimizer_name,'learning rate=',lr,'number of neurons=',neuron,'dropout rate =', dropRate,'achieved mean validation accuracy of',val_acc,' achieved mean validation loss of',val_loss)\n            try:\n                del model\n            except NameError:\n                pass\n        print('Best hyperparameters for the model',model_name,'with optimizer =',best_param['optimizer'],'learning rate=',best_param['lr'],'number of neurons=',best_param['neuron'],'dropout rate =', best_param['dropRate'],'achieved validation accuracy of',best_param['acc_score'])\n            \n\n    return best_param.values()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODELS\n# VGG16","metadata":{}},{"cell_type":"code","source":"def vgg16scratch(numclasses,input_shape=None,channel_dim=-1,initializer='he_normal',neuron=1024,dropRate=0.2):\n    image_input=layers.Input(shape=input_shape)\n    #Block 1:\n    x=layers.Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block1_Conv1')(image_input)\n    x=layers.Conv2D(64,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block1_Conv2')(x)\n    x=layers.MaxPooling2D((2,2),strides=(2,2),name='Block1_Pool')(x)\n    #Block 2:\n    x=layers.Conv2D(128,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block2_Conv1')(x)\n    x=layers.Conv2D(128,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block2_Conv2')(x)\n    x=layers.MaxPooling2D((2,2),strides=(2,2),name='Block2_Pool')(x)\n    #Block 3:\n    x=layers.Conv2D(256,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block3_Conv1')(x)\n    x=layers.Conv2D(256,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block3_Conv2')(x)\n    x=layers.Conv2D(256,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block3_Conv3')(x)\n    x=layers.MaxPooling2D((2,2),strides=(2,2),name='Block3_Pool')(x)\n    #Block 4:\n    x=layers.Conv2D(512,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block4_Conv1')(x)\n    x=layers.Conv2D(512,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block4_Conv2')(x)\n    x=layers.Conv2D(512,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block4_Conv3')(x)\n    x=layers.MaxPooling2D((2,2),strides=(2,2),name='Block4_Pool')(x)\n    #Block 5:\n    x=layers.Conv2D(512,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block5_Conv2')(x)\n    x=layers.Conv2D(512,(3,3),strides=(1,1),activation='relu',padding='same',kernel_initializer=initializer,name='Block5_Conv3')(x)\n    x=layers.MaxPooling2D((2,2),strides=(2,2),name='Block5_Pool')(x)\n   # x=layers.Flatten(name='flatten')(x)\n    x=layers.GlobalAveragePooling2D()(x)\n    x=layers.Dense(neuron,activation='relu',name='FC1',kernel_initializer=initializer,bias_initializer=initializer)(x)\n    x=layers.Dense(neuron,activation='relu',name='FC2',kernel_initializer=initializer,bias_initializer=initializer)(x)\n    x=layers.Dense(numclasses,activation='softmax',name='prediction')(x)\n    model=Model(image_input,x,name='vgg16')\n    print(model.summary())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paramGrid=[('SGD_Momentum',0.01,dl,0.2) for dl in neuron ]\nparamGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer_name,lr,neuron,dropRate,acc=gridSearch_ffd('vgg16',numclasses,paramGrid,chanDim=-1,batch_size=batch_size,epochs=epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_Scratch=vgg16scratch(numclasses,input_shape,-1,'he_normal',512,0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelVGG16Scratch=train_model('vgg16',vgg16_Scratch,optimizer,numclasses,X_Train, Y_Train,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_VGG16=train_model_ffd('vgg16',vgg16_Scratch,'SGD_Momentum',0.01,numclasses,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vgg16_pretrained(numclasses,input_shape,chanDim=-1,initializer='he_normal',neuron=1024,dropRate=0.2):\n    base_model=keras.applications.VGG16(include_top=False,\n                                        weights='imagenet',\n                                        input_shape=input_shape,\n                                        pooling='avg')\n     #base_model.load_weights(pathtoh5)\n    #for i,layer in enumerate(base_model.layers):\n        #print(i,layer.name)\n    for layer in base_model.layers[:11]:\n        layer.trainable=False\n    for layer in base_model.layers[11:]:\n        layer.trainable=True\n    x=base_model.output\n    x=layers.Dense(neuron,activation='relu',name='FC1',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n    x=layers.Dropout(rate=dropRate,name='Dropout_1')(x)\n    \n    x=layers.BatchNormalization(axis=chanDim,name='BatchNorm_1',beta_initializer=initializer,gamma_initializer=initializer,beta_regularizer=regularizers.l2(0.01),gamma_regularizer=regularizers.l2(0.01))(x)    \n    x=layers.Dense(neuron,activation='relu',name='FC2',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n    x=layers.Dropout(rate=dropRate,name='Dropout_2')(x)\n    \n    x=layers.BatchNormalization(axis=chanDim,name='BatchNorm_2',beta_initializer=initializer,gamma_initializer=initializer,beta_regularizer=regularizers.l2(0.01),gamma_regularizer=regularizers.l2(0.01))(x)  \n    x=layers.Activation('relu',name='Act_Relu_1')(x)\n    x=layers.Dense(numclasses,activation='softmax',name='Classification')(x)\n    model=Model(inputs=base_model.input,outputs=x,name='pretrained_vgg16')\n    print(model.summary())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paramGrid=[('SGD_Momentum',0.01,dl,dr) for dl in neuron for dr in dropRate]\nparamGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer_name,lr,neuron,dropRate,acc=gridSearch_ffd('pretrain_vgg16',numclasses,paramGrid,chanDim=-1,batch_size=batch_size,epochs=epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelVGG16Pretrained=vgg16_pretrained(numclasses,input_shape,-1,'he_normal',512,0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_VGG16Pretrained=train_model('pretrained_vgg16',modelVGG16Pretrained,optimizer,numclasses,X_Train, Y_Train,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_VGG16Pretrained=train_model_ffd('pretrain_vgg16',modelVGG16Pretrained,'SGD_Momentum',0.01,numclasses,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet50","metadata":{}},{"cell_type":"code","source":"def resnet50_pretrained(numclasses,input_shape,chanDim=-1,initializer='he_normal',neuron=1024,dropRate=0.2):\n    base_model=keras.applications.ResNet50(include_top=False,\n                                        weights='imagenet',\n                                        input_shape=input_shape,\n                                        pooling='avg')\n   # for i,layer in enumerate(base_model.layers):\n        #print(i,layer.name)\n    for layer in base_model.layers[:154]:\n        layer.trainable=False\n    for layer in base_model.layers[154:]:\n        layer.trainable=True\n    x=base_model.output\n    x=layers.Dense(neuron,activation='relu',name='FC1',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n    x=layers.BatchNormalization(axis=chanDim,name='BatchNorm_final',beta_initializer=initializer,gamma_initializer=initializer,beta_regularizer=regularizers.l2(0.01),gamma_regularizer=regularizers.l2(0.01))(x)  \n    x=layers.Activation('relu',name='Act_ReLu_final')(x)\n    x=layers.Dropout(rate=dropRate,name='Dropout_final')(x)\n    x=layers.Dense(numclasses,activation='softmax',name='Classification')(x)\n    model=Model(inputs=base_model.input,outputs=x,name='pretrain_ResNet50')\n    print(model.summary())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paramGrid=[('SGD_Nesterov',0.01,dl,dr) for dl in neuron for dr in dropRate]\nparamGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,optimizer_name,lr,neuron,dropRate,acc_score=gridSearch_ffd('pretrain_ResNet50',numclasses,paramGrid,chanDim=-1,batch_size=batch_size,epochs=epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelresnet50Pretrained=resnet50_pretrained(numclasses,input_shape,-1,'he_normal',512,0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_resnet50Pretrained=train_model('pretrain_ResNet50',modelresnet50Pretrained,optimizer,numclasses,X_Train, Y_Train,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_resnet50Pretrained=train_model_ffd('pretrain_ResNet50',modelresnet50Pretrained,'SGD_Nesterov',0.01,numclasses,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# InceptionV3","metadata":{}},{"cell_type":"code","source":"def inceptionv3_pretrained(numclasses,input_shape,chanDim=-1,initializer='he_normal',neuron=1024,dropRate=0.2):\n    base_model=keras.applications.InceptionV3(include_top=False,\n                                        weights='imagenet',\n                                        input_shape=input_shape,\n                                        pooling='avg')\n   # for i,layer in enumerate(base_model.layers):\n       # print(i,layer.name)\n    for layer in base_model.layers[:249]:\n        layer.trainable=False\n    for layer in base_model.layers[249:]:\n        layer.trainable=True\n    x=base_model.output\n    x=layers.Dense(neuron,activation='relu',name='FC1',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n    x=layers.BatchNormalization(axis=chanDim,name='BatchNorm_final',beta_initializer=initializer,gamma_initializer=initializer,beta_regularizer=regularizers.l2(0.01),gamma_regularizer=regularizers.l2(0.01))(x)  \n    x=layers.Activation('relu',name='Act_ReLu_final')(x)\n    x=layers.Dropout(rate=dropRate,name='Dropout_final')(x)\n    x=layers.Dense(numclasses,activation='softmax',name='Classification')(x)\n    model=Model(inputs=base_model.input,outputs=x,name='pretrain_InceptionV3')\n   # print(model.summary())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paramGrid=[('RMSprop',0.01,dl,dr) for dl in neuron for dr in dropRate]\nparamGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,optimizer_name,lr,neuron,dropRate,acc_score=gridSearch_ffd('pretrain_InceptionV3',numclasses,paramGrid,chanDim=-1,batch_size=batch_size,epochs=epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelinceptionv3Pretrained=inceptionv3_pretrained(numclasses,input_shape,-1,'he_normal',512,0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inceptionv3Pretrained=train_model('pretrain_InceptionV3',modelinceptionv3Pretrained,optimizer,numclasses,X_Train, Y_Train,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_inceptionv3Pretrained=train_model_ffd('pretrain_InceptionV3',modelinceptionv3Pretrained,'RMSprop',0.01,numclasses,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet121","metadata":{}},{"cell_type":"code","source":"def densenet121_pretrained(numclasses,input_shape,chanDim=-1,initializer='he_normal',neuron=1024,dropRate=0.2):\n    base_model=keras.applications.DenseNet121(include_top=False,\n                                        weights='imagenet',\n                                        input_shape=input_shape,\n                                        pooling='avg')\n   # for i,layer in enumerate(base_model.layers):\n        #print(i,layer.name)\n    \n    for layer in base_model.layers[:313]:\n        layer.trainable=False\n    for layer in base_model.layers[313:]:\n        layer.trainable=True\n    x=base_model.output\n    x=layers.Dense(neuron,activation='relu',name='FC1',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n    x=layers.BatchNormalization(axis=chanDim,name='BatchNorm_final',beta_initializer=initializer,gamma_initializer=initializer,beta_regularizer=regularizers.l2(0.01),gamma_regularizer=regularizers.l2(0.01))(x)  \n    x=layers.Activation('relu',name='Act_ReLu_final')(x)\n    x=layers.Dropout(rate=dropRate,name='Dropout_final')(x)\n    x=layers.Dense(numclasses,activation='softmax',name='Classification')(x)\n    model=Model(inputs=base_model.input,outputs=x,name='pretrain_DenseNet121')\n    #print(model.summary())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paramGrid=[('SGD_Nesterov',0.1,dl,dr) for dl in neuron for dr in dropRate ]\nparamGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,optimizer_name,lr,neuron,dropRate,acc_score=gridSearch_ffd('pretrain_DenseNet121',numclasses,paramGrid,chanDim=-1,batch_size=batch_size,epochs=epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modeldensenet121Pretrained=densenet121_pretrained(numclasses,input_shape,-1,'he_normal',512,0.4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_densenet121Pretrained=train_model('pretrain_DenseNet121',modeldensenet121Pretrained,optimizer,numclasses,X_Train, Y_Train,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_densenet121Pretrained=train_model_ffd('pretrain_DenseNet121',modeldensenet121Pretrained,'SGD_Nesterov',0.1,numclasses,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNet","metadata":{}},{"cell_type":"code","source":"def mobilenet_pretrained(numclasses,input_shape,chanDim=-1,initializer='he_normal',neuron=1024,dropRate=0.2):\n    base_model=keras.applications.MobileNet(include_top=False,\n                                        weights='imagenet',\n                                        input_shape=input_shape,\n                                        pooling='avg')\n    for i,layer in enumerate(base_model.layers):\n        print(i,layer.name)\n    for layer in base_model.layers[:44]:\n        layer.trainable=False\n    for layer in base_model.layers[44:]:\n        layer.trainable=True\n    x=base_model.output\n    x=layers.Dense(neuron,activation='relu',name='FC1',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n    x=layers.BatchNormalization(axis=chanDim,name='BatchNorm_final',beta_initializer=initializer,gamma_initializer=initializer,beta_regularizer=regularizers.l2(0.01),gamma_regularizer=regularizers.l2(0.01))(x)  \n    x=layers.Activation('relu',name='Act_ReLu_final')(x)\n    x=layers.Dropout(rate=dropRate,name='Dropout_final')(x)\n    x=layers.Dense(numclasses,activation='softmax',name='Classification')(x)\n    model=Model(inputs=base_model.input,outputs=x,name='pretrain_MobileNet')\n    print(model.summary())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paramGrid=[('RMSprop',0.001,dl,dr) for dl in neuron for dr in dropRate ]\nparamGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,optimizer_name,lr,neuron,dropRate,acc_score=gridSearch_ffd('pretrain_MobileNet',numclasses,paramGrid,chanDim=-1,batch_size=batch_size,epochs=epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelmobilenetPretrained=mobilenet_pretrained(numclasses,input_shape,-1,'he_normal',512,0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mobilenetPretrained=train_model('pretrain_MobileNet',modelmobilenetPretrained,optimizer,numclasses,X_Train, Y_Train,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mobilenetPretrained=train_model_ffd('pretrain_MobileNet',modelmobilenetPretrained,'RMSprop',0.001,numclasses,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# testNet","metadata":{}},{"cell_type":"code","source":"def conv2d_BNRelU(x, filters, kernelSize=(1,1), padding='same', strides=(1, 1),  name=None,chanDim=-1,initializer='he_normal'):\n    if name is not None:\n        bn_name = name + '_bn'\n        conv_name = name + '_conv'\n        act_name =name+'_act'\n    else:\n        bn_name = None\n        conv_name = None\n        act_name=None\n    x = layers.Conv2D(filters, kernelSize ,strides=strides,padding=padding,use_bias=False,kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.0002),name=conv_name)(x)\n    x = layers.BatchNormalization(axis=chanDim, scale=False, name=bn_name)(x)\n    x = layers.Activation('relu', name=act_name)(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv2dR_BNRelU(x, filters, kernelSize=(1,1), padding='same', strides=(1, 1),  name=None,chanDim=-1,initializer='he_normal'):\n    if name is not None:\n        bn_name = name + '_bn'\n        conv_name = name + '_conv'\n        act_name =name+'_act'\n    else:\n        bn_name = None\n        conv_name = None\n        act_name=None\n    x = layers.BatchNormalization(axis=chanDim, scale=False, name=bn_name)(x)\n    x = layers.Activation('relu', name=act_name)(x)\n    x = layers.Conv2D(filters, kernelSize ,strides=strides,padding=padding,use_bias=False,kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.0002),name=conv_name)(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def testNet(numclasses,input_shape=None,chanDim=-1,initializer='he_normal',neuron=1024,dropRate=0.2):\n    img_input = layers.Input(shape=input_shape)\n    #block 0\n    x=conv2d_BNRelU(img_input,32,(7,7),padding='same',strides=(2,2),name='Bl_0_conv7')\n    x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same',name='Bl_0_pool')(x)\n    \n    #block 1\n    x11=conv2d_BNRelU(x,64,(1,1),padding='valid',strides=(1,1),name='Bl_11_conv1')\n    \n    x12=conv2d_BNRelU(x,96,(1,1),padding='valid',strides=(1,1),name='Bl_12_conv1')\n    x12=conv2d_BNRelU(x12,192,(3,3),padding='same',strides=(1,1),name='Bl_12_conv3')\n    \n    x13=conv2d_BNRelU(x,32,(1,1),padding='valid',strides=(1,1),name='Bl_13_conv1')\n    x13=conv2d_BNRelU(x13,96,(5,5),padding='same',strides=(1,1),name='Bl_13_conv5')\n    \n    x14=conv2d_BNRelU(x,32,(1,1),padding='valid',strides=(1,1),name='Bl_14_conv1')\n    x14=conv2d_BNRelU(x14,96,(7,7),padding='same',strides=(1,1),name='Bl_14_conv7')\n    \n    x15=layers.MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='Bl_15_pool')(x)\n    x15=layers.BatchNormalization(axis=chanDim, epsilon=1.001e-5, momentum=0.9, beta_initializer=initializer,gamma_initializer=initializer, name= 'Bl_15_pool_bn')(x15)\n    x15=layers.Activation('relu', name='Bl_15_Pool_act')(x15)\n    x15=conv2d_BNRelU(x15,64,(1,1),padding='valid',strides=(1,1),name='Bl_15_conv1')\n\n    \n    #concatenation\n    x=keras.layers.concatenate([x11,x12,x13,x14,x15],axis=-1)\n    x=layers.MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='concat_1_pool')(x)\n    \n    #block 2\n    x21=conv2dR_BNRelU(x,128,(1,1),padding='valid',strides=(1,1),name='Bl_2a_conv1')\n    x21=conv2dR_BNRelU(x21,32,(3,3),padding='same',strides=(1,1),name='Bl_2a_conv3')\n    \n    #concatenate 21\n    x=keras.layers.concatenate([x,x21],axis=-1)\n    \n    x22=conv2dR_BNRelU(x,128,(1,1),padding='valid',strides=(1,1),name='Bl_2b_conv1')\n    x22=conv2dR_BNRelU(x22,32,(3,3),padding='same',strides=(1,1),name='Bl_2b_conv3')\n    \n    #concatenate 22\n    x=keras.layers.concatenate([x,x22],axis=-1)\n    \n    x23=conv2dR_BNRelU(x,128,(1,1),padding='valid',strides=(1,1),name='Bl_2c_conv1')\n    x23=conv2dR_BNRelU(x22,32,(3,3),padding='same',strides=(1,1),name='Bl_2c_conv3')\n    \n    #concatenate 23\n    x=keras.layers.concatenate([x,x23],axis=-1)\n    \n    #block 3\n    x=layers.BatchNormalization(axis=chanDim, epsilon=1.001e-5, momentum=0.9, beta_initializer=initializer,gamma_initializer=initializer, name= 'Bl_3_bn')(x)\n    x=layers.Activation('relu', name='Bl_3_dense_act')(x)\n    x=layers.Conv2D(int(int(x.shape[chanDim])*0.5),(1,1) ,strides=(1,1),padding='valid',use_bias=False,kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.0002),name='Bl_3_conv1')(x)\n\n    x=layers.Dropout(rate=dropRate,name='Dropout_1')(x)\n    x=layers.MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='valid',name='Bl_3_pool')(x)\n    x=layers.BatchNormalization(axis=chanDim, epsilon=1.001e-5, momentum=0.9, beta_initializer=initializer,gamma_initializer=initializer, name= 'Bl_3_Pool_bn')(x)\n    x=layers.Activation('relu', name='Bl_3_pool_act')(x)\n    \n    #block 4\n    x=conv2d_BNRelU(x,512,(1,1),padding='valid',strides=(1,1),name='Bl_4_conv1')\n    x=conv2d_BNRelU(x,1024,(3,3),padding='same',strides=(1,1),name='Bl_4_conv3')\n    x=conv2d_BNRelU(x,1024,(3,3),padding='same',strides=(1,1),name='Bl_4_conv3_1')\n    \n    x=layers.GlobalAveragePooling2D(name='global_avg_pool')(x)\n    \n    x=layers.Dense(neuron,activation='relu',name='FC1',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n\n    x=layers.BatchNormalization(axis=chanDim, epsilon=1.001e-5, momentum=0.9, beta_initializer=initializer,gamma_initializer=initializer, name= 'Bl_4_dense_bn')(x)\n    x=layers.Activation('relu', name='Bl_4_dense_act')(x)\n    x=layers.Dropout(rate=dropRate,name='Dropout_2')(x)\n    \n    x=layers.Dense(numclasses,activation='softmax',name='output',kernel_initializer=initializer,bias_initializer=initializer,use_bias=True,kernel_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(x)\n\n    model=Model(img_input,x,name='HCD-CNN')\n    print(model.summary())\n\n    return model\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paramGrid=[(o,l,dl,0.2) for o in optimizer_name  for l in lr for dl in neuron  ]\nparamGrid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model,optimizer_name,lr,neuron,dropRate,acc_score=gridSearch_ffd('HCD-CNN',numclasses,paramGrid,chanDim=-1,batch_size=batch_size,epochs=epochs)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modeltestNet=testNet(numclasses,input_shape,-1,'he_normal',1024,0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_testNet=train_model('HCD-CNN',modeltestNet,optimizer,numclasses,X_Train, Y_Train,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_testNet=train_model_ffd('HCD-CNN',modeltestNet,'SGD_Momentum',0.001,numclasses,chanDim=-1,batch_size=batch_size,epochs=epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def getTestGen(model_name,test_path,input_shape,batch_size=32):\n    height,width,channels = input_shape\n    preprocess_func = None\n    def zscoreNorm(x):\n        return (x - x.mean()) / x.std()  if x.std() > 0 else x\n    def minmax(x):\n        return x/255.0\n        \n    if model_name=='vgg16':\n        preprocess_func = minmax\n    if model_name=='pretrain_vgg16':\n        preprocess_func = keras.applications.vgg16.preprocess_input\n    if model_name=='pretrain_ResNet50':\n        preprocess_func = keras.applications.resnet.preprocess_input\n    if model_name=='pretrain_InceptionV3':\n        preprocess_func = keras.applications.inception_v3.preprocess_input\n    if model_name=='pretrain_DenseNet121':\n        preprocess_func = keras.applications.densenet.preprocess_input\n    if model_name=='pretrain_MobileNet':\n        preprocess_func = keras.applications.mobilenet.preprocess_input\n    if model_name=='HCD-CNN':\n        preprocess_func = minmax\n\n    datagenTest = ImageDataGenerator(preprocessing_function=preprocess_func )\n    test_gen = datagenTest.flow_from_directory(testPath,\n                                                        target_size=(height,width),\n                                                        batch_size=batch_size,\n                                                        shuffle=False,\n                                                        interpolation='lanczos',\n                                                        class_mode='categorical')\n   \n    return test_gen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weightsPath='./'\ndef evaluateModelGenFFD(model_name,input_shape,num_samples,batch_size=256):\n    model = load_model(weightsPath+model_name+\".h5\")\n    testGen = getTestGen(model_name,testPath,input_shape,batch_size=32)\n    val_loss, val_acc = model.evaluate_generator(testGen,steps=np.ceil(num_samples/batch_size),verbose=1)\n    print('Validation on Test Set: Validation Loss =',val_loss,'Validation Accuracy =',val_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModelGenFFD('vgg16',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModelGenFFD('pretrain_vgg16',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModelGenFFD('pretrain_ResNet50',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModelGenFFD('pretrain_InceptionV3',input_shape,num_test_samples,batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModelGenFFD('pretrain_DenseNet121',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModelGenFFD('pretrain_MobileNet',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluateModelGenFFD('HCD-CNN',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"pathToPredictions='./'\ndef predictGenFFD(model_name,input_shape,num_samples,batch_size=32): \n    model = load_model(weightsPath+model_name+\".h5\")\n    testGen = getTestGen(model_name,testPath,input_shape,batch_size=256)\n    Y_Pred_Probs = model.predict_generator(testGen,steps=np.ceil(num_samples/batch_size), verbose=1)\n    \n    #Converting to Interger Encoding by getting the index of Maximum Probability Column\n    Y_pred = np.argmax(Y_Pred_Probs,axis = 1)\n    Y_True = testGen.classes\n    filenames = testGen.filenames\n    labels = testGen.class_indices\n    labels = dict((v,k) for k,v in labels.items())\n    Y_pred_ClassNames = [labels[k] for k in Y_pred]\n    Y_true_ClassNames = [labels[k] for k in Y_True]\n    probDF = pd.DataFrame(data=list(Y_Pred_Probs),columns=list(labels.values()))\n    results=pd.DataFrame({\"Filename\":filenames,\n                          \"True Class Names\":Y_true_ClassNames,\n                          \"Predicted Class Names\":Y_pred_ClassNames,\n                          \"True Class Labels\":Y_True,\n                          \"Predicted Class Labels\":Y_pred})\n    results = pd.concat([results,probDF],axis=1)\n    results.to_csv(f\"{pathToPredictions}{model_name}results.csv\",index=False)\n    del model\n    del testGen\n    return Y_True, Y_pred, Y_Pred_Probs, labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_True, Y_Pred, Y_Pred_Probs, labels = predictGenFFD('vgg16',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_test_samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_True, Y_Pred, Y_Pred_Probs, labels = predictGenFFD('pretrain_vgg16',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_True, Y_Pred, Y_Pred_Probs, labels = predictGenFFD('pretrain_ResNet50',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_True, Y_Pred, Y_Pred_Probs, labels = predictGenFFD('pretrain_InceptionV3',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_True, Y_Pred, Y_Pred_Probs, labels = predictGenFFD('pretrain_DenseNet121',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_True, Y_Pred, Y_Pred_Probs, labels = predictGenFFD('pretrain_MobileNet',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_True, Y_Pred, Y_Pred_Probs, labels = predictGenFFD('HCD-CNN',input_shape,num_test_samples,batch_size=256)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion matrix","metadata":{}},{"cell_type":"code","source":"pathToFigures='./'\nimport itertools\ndef plot_confusion_matrix(cm, classes, model_name):\n    normalize=False\n    title='Confusion Matrix for '+model_name\n    cmap=plt.cm.Oranges\n    plt.figure(figsize=(6,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=20)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, fontsize=12)\n    plt.yticks(tick_marks, classes, fontsize=12)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label',fontsize=14)\n    plt.xlabel('Predicted label',fontsize=14)\n    plt.savefig(f'{pathToFigures}confMatrix_{model_name}.jpg',dpi=150,bbox_inches='tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_True, Y_Pred)\n\nplot_confusion_matrix(confusion_mtx, list(labels.values()),'vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_True, Y_Pred)\n\nplot_confusion_matrix(confusion_mtx, list(labels.values()),'pretrain_vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_True, Y_Pred)\n\nplot_confusion_matrix(confusion_mtx, list(labels.values()),'pretrain_ResNet50')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_True, Y_Pred)\n\nplot_confusion_matrix(confusion_mtx, list(labels.values()),'pretrain_InceptionV3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_True, Y_Pred)\n\nplot_confusion_matrix(confusion_mtx, list(labels.values()),'pretrain_DenseNet121')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_True, Y_Pred)\n\nplot_confusion_matrix(confusion_mtx, list(labels.values()),'pretrain_MobileNet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_mtx = confusion_matrix(Y_True, Y_Pred)\n\nplot_confusion_matrix(confusion_mtx, list(labels.values()),'HCD-CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Accracy, F1 score, recall, precision","metadata":{}},{"cell_type":"code","source":"def getPrecisionRecallFScoreSupport(y_true, y_pred):\n    prfsMacro = precision_recall_fscore_support(y_true, y_pred, average='macro')\n    prfsMicro = precision_recall_fscore_support(y_true, y_pred, average='micro')\n    prfsWeighted = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n    print('Macro Precision:',prfsMacro[0],'Recall',prfsMacro[1],'F1-Score',prfsMacro[2],'Support',prfsMacro[3])\n    print('Micro Precision:',prfsMicro[0],'Recall',prfsMicro[1],'F1-Score',prfsMicro[2],'Support',prfsMicro[3])\n    print('Weighted Precision:',prfsWeighted[0],'Recall',prfsWeighted[1],'F1-Score',prfsWeighted[2],'Support',prfsWeighted[3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"getPrecisionRecallFScoreSupport(Y_True, Y_Pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(Y_True, Y_Pred,target_names=list(labels.values())))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Accuracy:',accuracy_score(Y_True, Y_Pred))\nprint('Balanced Accuracy:',balanced_accuracy_score(Y_True, Y_Pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC curves","metadata":{}},{"cell_type":"code","source":"\nfrom itertools import cycle\ndef roc_curve_multiClassOneVsRestMicro(Y_pred_probs,Y_true,num_classes,labels,model_name):\n    classes = list(labels.values())\n    #Y_true = t(Y_true, classes=list(np.arange(num_classes)))\n    Y_true = to_categorical(Y_true, num_classes = num_classes,dtype='float64')\n\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    closest_one = dict()\n    closest_one_tpr = dict()\n    closest_one_fpr = dict()\n    for i in range(num_classes):\n        fpr[i], tpr[i],_= roc_curve(Y_true[:, i], Y_pred_probs[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n        closest_one[i] = np.argmax(np.abs(tpr[i]))\n        closest_one_tpr[i] = tpr[i][closest_one[i]]\n        closest_one_fpr[i] = fpr[i][closest_one[i]]\n\n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_true.ravel(), Y_pred_probs.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    closest_one[\"micro\"] = np.argmax(np.abs(tpr[\"micro\"]))\n    closest_one_tpr[\"micro\"] = tpr[\"micro\"][closest_one[\"micro\"]]\n    closest_one_fpr[\"micro\"] = fpr[\"micro\"][closest_one[\"micro\"]]\n    if num_classes%2==0:\n        rows=int(np.ceil(num_classes/2))+1\n    else:\n        rows=int(np.ceil(num_classes/2))\n    cols=2\n    plt.tight_layout()\n    lw = 2\n    plt.figure(figsize=(6*cols,5*rows))\n    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n    colors = cycle(['navy', 'darkorange', 'cornflowerblue','brown','purple','green','pink','cyan'])\n    for i, color in zip(range(num_classes), colors):\n        color = color\n        pos=int(str(rows)+str(cols)+str(i+1))\n        ax=plt.subplot(pos)\n        ax.plot(fpr[i], tpr[i], color=color,\n                 lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[i])\n        ax.plot(closest_one_fpr[i], closest_one_tpr[i], '.', markersize = 12, fillstyle = 'none', c=color, mew=3)   \n        \n        ax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n        ax.set_xlim([-0.01, 1.00])\n        ax.set_ylim([-0.01, 1.01])\n        ax.set_xlabel('False Positive Rate', fontsize=14)\n        ax.set_ylabel('True Positive Rate', fontsize=14)\n        ax.set_title(f'ROC Curve for Class:{classes[i]}', fontsize=16)\n        ax.legend(loc=\"lower right\", fontsize=14)\n        ax.tick_params(labelsize=12)\n        ax.set_aspect('equal')\n    pos=int(str(rows)+str(cols)+str(i+2))\n    ax=plt.subplot(pos)\n    ax.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC Curve (area = {0:0.2f})'\n                   ''.format(roc_auc[\"micro\"]),\n             color='red', linestyle='--', linewidth=2)\n    ax.plot(closest_one_fpr[\"micro\"], closest_one_tpr[\"micro\"], '.', markersize = 12, fillstyle = 'none', c='r', mew=3)\n    ax.set_xlim([-0.01, 1.00])\n    ax.set_ylim([-0.01, 1.01])\n    ax.set_xlabel('False Positive Rate', fontsize=14)\n    ax.set_ylabel('True Positive Rate', fontsize=14)\n    ax.set_title(f'ROC Curve: Micro-Average', fontsize=16)\n    ax.legend(loc=\"lower right\", fontsize=14)\n    ax.tick_params(labelsize=12)\n    ax.set_aspect('equal')\n    plt.savefig(f'{pathToFigures}ROC_OVR_Micro_{model_name}.jpg',dpi=150,bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_ResNet50')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_InceptionV3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_DenseNet121')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_MobileNet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'HCD-CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def roc_curve_multiClassOneVsOneMacro(Y_pred_probs,Y_true,num_classes,labels,model_name):\n    classes = list(labels.values())\n    Y_true = to_categorical(Y_true, num_classes = num_classes,dtype='float64')\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    closest_one = dict()\n    closest_one_tpr = dict()\n    closest_one_fpr = dict()\n    for i in range(num_classes):\n        fpr[i], tpr[i], thresholds = roc_curve(Y_true[:, i], Y_pred_probs[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n        closest_one[i] = np.argmax(np.abs(tpr[i]))\n        closest_one_tpr[i] = tpr[i][closest_one[i]]\n        closest_one_fpr[i] = fpr[i][closest_one[i]]\n        \n        \n    # Compute micro-average ROC curve and ROC area\n    fpr[\"micro\"], tpr[\"micro\"], thresholds = roc_curve(Y_true.ravel(), Y_pred_probs.ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n    closest_one[\"micro\"] = np.argmax(np.abs(tpr[\"micro\"]))\n    closest_one_tpr[\"micro\"] = tpr[\"micro\"][closest_one[\"micro\"]]\n    closest_one_fpr[\"micro\"] = fpr[\"micro\"][closest_one[\"micro\"]]\n    # First aggregate all false positive rates\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n\n    # Then interpolate all ROC curves at this points\n    mean_tpr = np.zeros_like(all_fpr)\n    for i in range(num_classes):\n        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n    # Finally average it and compute AUC\n    mean_tpr /= num_classes\n\n    fpr[\"macro\"] = all_fpr\n    tpr[\"macro\"] = mean_tpr\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n    # Plot all ROC curves\n    plt.figure(figsize=(10,10))\n    lw = 2\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='Micro-Average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]),\n             color='red', linestyle=':', linewidth=4)\n    plt.plot(closest_one_fpr[\"micro\"], closest_one_tpr[\"micro\"], '.', markersize = 12, fillstyle = 'none', c='r', mew=3)\n    \n    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n             label='Macro-Average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]),\n             color='navy', linestyle=':', linewidth=4)\n\n    colors = cycle(['aqua', 'darkorange', 'cornflowerblue','brown','purple','green','pink','cyan'])\n    for i, color in zip(range(num_classes), colors):\n        color = color\n        plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC Curve of class {0} (area = {1:0.2f})'.format(classes[i], roc_auc[i]))\n        plt.plot(closest_one_fpr[i], closest_one_tpr[i], '.', markersize = 12, fillstyle = 'none', c=color, mew=3)   \n        \n    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n    plt.axes().set_aspect('equal')\n    plt.xlim([-0.01, 1.00])\n    plt.ylim([-0.01, 1.01])\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel('False Positive Rate', fontsize=20)\n    plt.ylabel('True Positive Rate', fontsize=20)\n    plt.title('Receiver Operating Characteristic Curve', fontsize=24)\n    plt.legend(loc=\"lower right\", fontsize=16)\n    plt.savefig(f'{pathToFigures}ROC_OVO_Macro_{model_name}.jpg',dpi=150,bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsOneMacro(Y_Pred_Probs,Y_True,numclasses,labels,'vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsOneMacro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsOneMacro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_ResNet50')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsOneMacro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_InceptionV3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsOneMacro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_DenseNet121')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsOneMacro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_MobileNet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve_multiClassOneVsOneMacro(Y_Pred_Probs,Y_True,numclasses,labels,'HCD-CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pr_curve_multiClassOneVsRestMicro(Y_pred_probs,Y_true,num_classes,labels,model_name):\n    classes = list(labels.values())\n    Y_true = to_categorical(Y_true, num_classes = num_classes,dtype='float64')\n    # Compute ROC curve and ROC area for each class\n    p = dict()\n    r = dict()\n    closest_zero = dict()\n    closest_zero_p = dict()\n    closest_zero_r = dict()\n    average_precision = dict()\n    pr_auc = dict()\n    for i in range(num_classes):\n        p[i], r[i], thresholds = precision_recall_curve(Y_true[:, i], Y_pred_probs[:, i])\n        average_precision[i] = average_precision_score(Y_true[:, i], Y_pred_probs[:, i])\n        closest_zero[i] = np.argmin(np.abs(thresholds))\n        closest_zero_p[i] = p[i][closest_zero[i]]\n        closest_zero_r[i] = r[i][closest_zero[i]]\n    # Compute micro-average ROC curve and ROC area\n    p[\"micro\"], r[\"micro\"], thresholds = precision_recall_curve(Y_true.ravel(), Y_pred_probs.ravel())\n    average_precision[\"micro\"] = average_precision_score(Y_true, Y_pred_probs, average=\"micro\")\n    closest_zero[\"micro\"] = np.argmin(np.abs(thresholds))\n    closest_zero_p[\"micro\"] = p[\"micro\"][closest_zero[\"micro\"]]\n    closest_zero_r[\"micro\"] = r[\"micro\"][closest_zero[\"micro\"]]\n    if num_classes%2==0:\n        rows=int(np.ceil(num_classes/2))+1\n    else:\n        rows=int(np.ceil(num_classes/2))\n    cols=2\n    plt.tight_layout()\n    lw = 2\n    plt.figure(figsize=(6*cols,5*rows))\n    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n    for i in range(num_classes):\n        pos=int(str(rows)+str(cols)+str(i+1))\n        ax=plt.subplot(pos)\n        ax.set_aspect('equal')\n        ax.plot(r[i], p[i], color='darkorange', lw=lw, label='PR curve (AP = %0.2f)' % average_precision[i])\n        ax.plot(closest_zero_r[i], closest_zero_p[i], 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n        ax.set_xlim([-0.01, 1.00])\n        ax.set_ylim([-0.01, 1.01])\n        ax.set_xlabel('Recall', fontsize=14)\n        ax.set_ylabel('Precision', fontsize=14)\n        ax.set_title(f'Precision Recall Curve for Class:{classes[i]}', fontsize=16)\n        ax.legend(loc=\"lower right\", fontsize=14)\n        ax.tick_params(labelsize=12)\n    pos=int(str(rows)+str(cols)+str(i+2))\n    ax=plt.subplot(pos)\n    ax.set_aspect('equal')\n    ax.plot(r[\"micro\"], p[\"micro\"], color='red', linestyle='--', linewidth=2, label='PR curve Micro-avg. (AP = %0.2f)' % average_precision[\"micro\"])\n    ax.plot(closest_zero_r[\"micro\"], closest_zero_p[\"micro\"], 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n    ax.set_xlim([-0.01, 1.00])\n    ax.set_ylim([-0.01, 1.01])\n    ax.set_xlabel('Recall', fontsize=14)\n    ax.set_ylabel('Precision', fontsize=14)\n    ax.set_title('PR Curve: Micro-avg. over all classes', fontsize=16)\n    ax.legend(loc=\"lower right\", fontsize=14)\n    ax.tick_params(labelsize=12)\n    plt.savefig(f'{pathToFigures}PR_OVR_Micro_{model_name}.jpg',dpi=150,bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_ResNet50')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_InceptionV3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_DenseNet121')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_MobileNet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsRestMicro(Y_Pred_Probs,Y_True,numclasses,labels,'HCD-CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pr_curve_multiClassOneVsOne(Y_pred_probs,Y_true,num_classes,labels,model_name):\n    classes = list(labels.values())\n   # Y_true = label_binarize(Y_true, classes=list(np.arange(num_classes)))\n    Y_true = to_categorical(Y_true, num_classes = num_classes,dtype='float64')\n\n    # Compute ROC curve and ROC area for each class\n    p = dict()\n    r = dict()\n    lines = []\n    labels = []\n    closest_zero = dict()\n    closest_zero_p = dict()\n    closest_zero_r = dict()\n    f_scores = np.linspace(0.2, 0.8, num=4)\n    plt.figure(figsize=(10,10))\n    plt.subplots_adjust(bottom=0.25)\n    for f_score in f_scores:\n        x = np.linspace(0.01, 1)\n        y = f_score * x / (2 * x - f_score)\n        l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n        plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))\n\n    lines.append(l)\n    labels.append('iso-f1 curves')\n    \n    average_precision = dict()\n    for i in range(num_classes):\n        p[i], r[i], thresholds = precision_recall_curve(Y_true[:, i], Y_pred_probs[:, i])\n        closest_zero[i] = np.argmin(np.abs(thresholds))\n        closest_zero_p[i] = p[i][closest_zero[i]]\n        closest_zero_r[i] = r[i][closest_zero[i]]\n        average_precision[i] = average_precision_score(Y_true[:, i], Y_pred_probs[:, i])\n        \n\n    # Compute micro-average ROC curve and ROC area\n    p[\"micro\"], r[\"micro\"], thresholds = precision_recall_curve(Y_true.ravel(), Y_pred_probs.ravel())\n    average_precision[\"micro\"] = average_precision_score(Y_true, Y_pred_probs, average=\"micro\")\n    closest_zero[\"micro\"] = np.argmin(np.abs(thresholds))\n    closest_zero_p[\"micro\"] = p[\"micro\"][closest_zero[\"micro\"]]\n    closest_zero_r[\"micro\"] = r[\"micro\"][closest_zero[\"micro\"]]\n    # Plot all ROC curves\n    \n    lw = 2\n    l, = plt.plot(r[\"micro\"], p[\"micro\"],lw=lw,color='red', linestyle=':', linewidth=4)\n    plt.plot(closest_zero_r[\"micro\"], closest_zero_p[\"micro\"], 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n    lines.append(l)\n    labels.append('micro-average Precision-recall (area = {0:0.2f})'.format(average_precision[\"micro\"]))\n    \n    colors = cycle(['navy','turquoise','teal', 'darkorange', \n                    'cornflowerblue','brown','purple','green','pink','cyan'])\n    for i, color in zip(range(num_classes), colors):\n        l, = plt.plot(r[i], p[i], color=color, lw=lw)\n        lines.append(l)\n        plt.plot(closest_zero_r[i], closest_zero_p[i], 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)   \n        labels.append('Precision-recall for class {0} (area = {1:0.2f})'.format(classes[i], average_precision[i]))\n\n    plt.xlim([-0.01, 1.00])\n    plt.ylim([-0.01, 1.01])\n    plt.xticks(fontsize=14)\n    plt.yticks(fontsize=14)\n    plt.xlabel('Recall', fontsize=20)\n    plt.ylabel('Precision', fontsize=20)\n    plt.title('Precision vs. Recall Curve', fontsize=24)\n    plt.legend(lines, labels, loc=(0, -.58), fontsize=16)\n    plt.axes().set_aspect('equal')\n    plt.savefig(f'{pathToFigures}PR_OVO_Micro_{model_name}.jpg',dpi=150,bbox_inches='tight')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsOne(Y_Pred_Probs,Y_True,numclasses,labels,'vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsOne(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsOne(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_ResNet50')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsOne(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_InceptionV3')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsOne(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_DenseNet121')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsOne(Y_Pred_Probs,Y_True,numclasses,labels,'pretrain_MobileNet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pr_curve_multiClassOneVsOne(Y_Pred_Probs,Y_True,numclasses,labels,'HCD-CNN')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting Class of New Test image:","metadata":{}},{"cell_type":"code","source":"lesion_type_dict = {\n    0: 'No Cancer',\n    1: 'Cancer'\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_input(model_name,X):\n    height,width,channels = X.shape\n    preprocess_func = None\n    def zscoreNorm(x):\n        return (x - x.mean()) / x.std()  if x.std() > 0 else x\n    def minmax(x):\n        return x/255.0\n        \n    if model_name=='vgg16':\n        preprocess_func = minmax\n    if model_name=='pretrain_vgg16':\n        preprocess_func = keras.applications.vgg16.preprocess_input\n    if model_name=='pretrain_ResNet50':\n        preprocess_func = keras.applications.resnet.preprocess_input\n    if model_name=='pretrain_InceptionV3':\n        preprocess_func = keras.applications.inception_v3.preprocess_input\n    if model_name=='pretrain_DenseNet121':\n        preprocess_func = keras.applications.densenet.preprocess_input\n    if model_name=='pretrain_MobileNet':\n        preprocess_func = keras.applications.mobilenet.preprocess_input\n    if model_name=='HCD-CNN':\n        preprocess_func = minmax\n\n    return preprocess_func(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weightsPath='./'\ndef predictOnImage(img_path,model_name,input_shape):\n    ### END CODE HERE ###\n    img = image.load_img(img_path, target_size=(input_shape[0], input_shape[1]))\n    imshow(img)\n    \n    model = load_model(weightsPath+model_name+\".h5\")\n    \n    x = np.array(img)\n    #x = image.img_to_array(img)\n    x = preprocess_input(model_name, x)\n    imshow(Image.fromarray(x))\n    x = np.expand_dims(x, axis=0)\n    pred = model.predict(x)\n    pred = np.argmax(pred,axis = 1)\n    pred = lesion_type_dict[lbls_present[pred[0]]]\n    print(f'The image {img_path} is {pred}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictOnImage(\"your_path_to_image\",'HCD-CNN',input_shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"height=96\nwidth=96\ndepth=3\ninput_shape = (height, width, depth)\nchanDim = -1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    os.mkdir('img_dirAll')\nexcept FileExistsError:\n    pass\n#img_dir=os.path.join('../input/output/','img_dirAll')\nimg_dir='img_dirAll/'\ndfData=shuffle(pd.concat([filenames,labels],axis=1).reset_index(drop=True))\nfor subf in ['0','1']:\n    try:\n        os.makedirs(os.path.join(img_dir, subf))\n    except FileExistsError:\n        pass\nsrc_path='../input/histopathologic-cancer-detection/train'\n\nfor i in range(len(dfData)):\n    fname=dfData.iloc[i,0] + '.tif'\n    label=dfData.iloc[i,1]\n    src = os.path.join(src_path, fname)\n    dst = os.path.join(img_dir, str(label), fname)\n    shutil.copyfile(src, dst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testPath='../input/histopathological-cancer-detection-weights/test/test'\n\ndef getFeatures(model_name,weightPath,pathToEF,input_shape,path,noOfSamples):\n    base_model = load_model(weightPath+model_name+\".h5\")\n    if  model_name=='vgg16' or model_name=='VGG16Pretrained':\n        featureLayer='FC2'\n    else:\n        featureLayer='Act_ReLU_final'\n    model = Model(inputs=base_model.input, outputs=base_model.get_layer(featureLayer).output)\n    dataGen = getTestGen(model_name,path,input_shape,batch_size=32)\n    X_features = model.predict_generator(dataGen,steps=np.ceil(noOfSamples/batch_size), verbose=1)\n    Y_True = dataGen.classes\n    filenames = dataGen.filenames\n    labels = dataGen.class_indices\n    labels = dict((v,k) for k,v in labels.items())\n    Y_true_ClassNames = [labels[k] for k in Y_True]\n        \n    cols = list(range(X_features.shape[1]))\n    featureDF = pd.DataFrame(data=list(X_features),columns=cols)\n    results=pd.DataFrame({\"Filename\":filenames,\n                            \"True Class Names\":Y_true_ClassNames,\n                            \"True Class Labels\":Y_True})\n    results = pd.concat([results,featureDF],axis=1)\n    results.to_csv(f\"{pathToExtractedFeatures}{model_name}Features.csv\",index=False)\n    del dataGen    \n    del model\n    del base_model\n    return results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weightsPath='../input/histopathological-cancer-detection-weights/'\nnum_samples = len(dfData)\npathToExtractedFeatures = './'\ngetFeatures('vgg16',weightsPath,pathToExtractedFeatures,input_shape,img_dir,num_samples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_DatasetFromTrainedModel(model_name,pathToEF):\n    dfDataSet = pd.read_csv(f\"{pathToEF}{model_name}Features.csv\")\n    dfDataSet=shuffle(dfDataSet)\n    print (\"Dataset Length: \", len(dfDataSet)) \n    print (\"Dataset Shape: \", dfDataSet.shape) \n    print(dfDataSet.head(10))\n    X = dfDataSet.iloc[:,3:-1]\n    Y = dfDataSet.iloc[:,2]\n    X_trn, X_test,Y_trn, Y_test = train_test_split(X,Y, test_size=0.10, random_state=101, shuffle=True, stratify=Y) \n    X_train,X_val,Y_train,Y_val = train_test_split(X_trn,Y_trn, test_size=0.10, random_state=101, shuffle=True, stratify=Y_trn)\n    \n    classCountsTrain=pd.DataFrame(np.array(np.unique(Y_train, return_counts=True)).T, columns=['Class','Freq']).set_index('Class')\n    classCountsTrain['Freq'] = classCountsTrain['Freq'] / np.sum(classCountsTrain['Freq'])\n\n    #print(classCountsTrain)\n    classCountsTrain.plot(kind='bar',label='Class',color=[['royalblue', 'ORANGERED', 'purple', 'GOLD', 'purple','SLATEBLUE','LIMEGREEN']])\n    plt.title('Class Proportion in Training:')\n    plt.xlabel('dx')\n    plt.ylabel('Counts')\n    plt.grid(axis='y')\n\n    classCountsVal=pd.DataFrame(np.array(np.unique(Y_val, return_counts=True)).T, columns=['Class','Freq']).set_index('Class')\n    classCountsVal['Freq'] = classCountsVal['Freq'] / np.sum(classCountsVal['Freq'])\n    #print(classCountsVal)\n    classCountsVal.plot(kind='bar', label='Class', color=[['royalblue', 'ORANGERED', 'purple', 'GOLD', 'purple','SLATEBLUE','LIMEGREEN']])\n    plt.title('Class Proportion in Validation:')\n    plt.xlabel('dx')\n    plt.ylabel('Counts')\n    plt.grid(axis='y')\n    return X_train,Y_train, X_val, Y_val, X_test, Y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_DatasetFromTrainedModel(model_name,pathToEF):\n    dfDataSet = pd.read_csv(f\"{pathToEF}{model_name}Features.csv\", header=None)\n    dfDataSet=shuffle(dfDataSet)\n    print (\"Dataset Length: \", len(dfDataSet)) \n    print (\"Dataset Shape: \", dfDataSet.shape) \n    print(dfDataSet.head(10))\n    X = dfDataSet.iloc[:,3:-1]\n    sc_X = StandardScaler()\n    X = sc_X.fit_transform(X)\n    Y = dfDataSet.iloc[:,2]\n    X_train, X_test,Y_train, Y_test = train_test_split(X,Y, test_size=0.10, random_state=101, shuffle=True, stratify=Y) \n    \n    classCountsTrain=pd.DataFrame(np.array(np.unique(Y_train, return_counts=True)).T, columns=['Class','Freq']).set_index('Class')\n    classCountsTrain['Freq'] = classCountsTrain['Freq'] / np.sum(classCountsTrain['Freq'])\n\n    #print(classCountsTrain)\n    classCountsTrain.plot(kind='bar',label='Class',color=[['royalblue', 'ORANGERED', 'purple', 'GOLD', 'purple','SLATEBLUE','LIMEGREEN']])\n    plt.title('Class Proportion in Training:')\n    plt.xlabel('dx')\n    plt.ylabel('Counts')\n    plt.grid(axis='y')\n\n    classCountsVal=pd.DataFrame(np.array(np.unique(Y_test, return_counts=True)).T, columns=['Class','Freq']).set_index('Class')\n    classCountsVal['Freq'] = classCountsVal['Freq'] / np.sum(classCountsVal['Freq'])\n    #print(classCountsVal)\n    classCountsVal.plot(kind='bar', label='Class', color=[['royalblue', 'ORANGERED', 'purple', 'GOLD', 'purple','SLATEBLUE','LIMEGREEN']])\n    plt.title('Class Proportion in Validation:')\n    plt.xlabel('dx')\n    plt.ylabel('Counts')\n    plt.grid(axis='y')\n    return X_train,Y_train, X_test, Y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" X_train,Y_train, X_val, Y_val, X_test, Y_test=get_DatasetFromTrainedModel('vgg16',pathToExtractedFeatures)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Vector Machine Classifier:\n<img src='images/svm.jpg' style='height=399px;width=703px'>\n\n### sklearn.svm.SVC:\n - *Support Vector Classification.*\n - The multiclass support is handled according to a one-vs-one scheme.\n - *Parameters:*\n    - *C:* float, default=1.0, *Regularization parameter*. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty.\n    - *kernel:* {linear, poly, rbf, sigmoid, precomputed}, default=rbf\n    - degree: int, default=3, Degree of the polynomial kernel function (poly). Ignored by all other kernels.\n    - *gamma:* {scale, auto} or float, default=scale, Kernel coefficient for rbf, poly and sigmoid.\n        - if gamma='scale' (default) is passed then it uses 1 / (n_features * X.var()) as value of gamma,\n        - if auto, uses 1 / n_features.\n    - coef0: float, default=0.0, Independent term in kernel function. It is only significant in poly and sigmoid.\n    - *degree:* int, default=3, Degree of the polynomial kernel function (poly). Ignored by all other kernels.\n    - *probability:* bool, default=False, Whether to enable probability estimates. \n      - This must be enabled prior to calling fit.\n      - It will slow down that method as it internally uses 5-fold cross-validation.\n      - And predict_proba may be inconsistent with predict.\n    - *decision_function_shape:* {ovo, ovr}, default=ovr. \n      - Whether to return a one-vs-rest (ovr) decision function of shape (n_samples, n_classes) as all other classifiers.\n      - Or the original one-vs-one (ovo) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). \n      - However, one-vs-one (ovo) is always used as multi-class strategy. The parameter is ignored for binary classification.\n    - *class_weight:* dict or balanced, default=None. \n      - Set the parameter C of class i to class_weight[i]*C for SVC. \n      - If not given, all classes are supposed to have weight one. \n      - The *balanced* mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))\n - *Attributes:*\n    - *support_:* ndarray of shape (n_SV,), *Indices of support vectors*.\n    - *support_vectors_:* ndarray of shape (n_SV, n_features), *Support vectors.*\n    - *n_support_:* ndarray of shape (n_class,), dtype=int32, Number of support vectors for each class.\n    - *classes_:* ndarray of shape (n_classes,). The classes labels.\n - *Methods:*\n   - *fit(X, y, sample_weight=None):* Fit the SVM model according to the given training data.\n   - *predict(X):* Perform classification on samples in X. Returns *y_pred* a ndarray of shape *(n_samples,)*, Class labels for samples in X.\n   - *score(X, y[, sample_weight]):* Return the mean accuracy on the given test data and labels.\n     - *Returns:*\n       - *score:* float, Mean accuracy of self.predict(X) wrt. y.\n - *Property:*\n   - *predict_proba(X):* Compute probabilities of possible outcomes for samples in X. The model need to have probability information computed at training time: fit with attribute probability set to True.\n     - *Returns:*\n       - *T:* ndarray of shape (n_samples, n_classes). \n         - Returns the probability of the sample for each class in the model. \n         - The columns correspond to the classes in sorted order, as they appear in the attribute classes_.","metadata":{}},{"cell_type":"code","source":"#Simple SVC:\nsvmClf = SVC(kernel='rbf', gamma='scale', class_weight='balanced', decision_function_shape='ovr')\nsvmClf.fit(X_train,Y_train)\nprint('Accuracy Score: ', svmClf.score(X_test, Y_test))\nprint(\"#Support Vectors:\",sum(svmClf.n_support_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grid Search:","metadata":{}},{"cell_type":"code","source":"grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100,'scale'], 'C':[0.01, 1, 10]}\nsvmClf = SVC(kernel='rbf', class_weight='balanced', decision_function_shape='ovr', probability=True)\ngrid_clf_acc = GridSearchCV(svmClf, param_grid = grid_values)\ngrid_clf_acc.fit(X_train,Y_train)\nprint('Grid best parameter (max. accuracy): ', grid_clf_acc.best_params_)\nprint('Grid best score (accuracy): ', grid_clf_acc.best_score_)\nprint('Score (ACC): ', grid_clf_acc.score(X_test, Y_test))\nprint(\"#Support Vectors:\",sum(grid_clf_acc.n_support_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_clf_auc = GridSearchCV(svmClf, param_grid = grid_values, scoring = 'roc_auc')\ngrid_clf_auc.fit(X_train,Y_train)\nprint('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\nprint('Grid best score (AUC): ', grid_clf_auc.best_score_)\nprint('Score (AUC): ', grid_clf_auc.score(X_test, Y_test))\nprint(\"#Support Vectors:\",sum(grid_clf_auc.n_support_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,Y_train, X_test, Y_test = get_DatasetFromTrainedModel('vgg16',pathToExtractedFeatures)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_Pred=grid_clf_auc.predict(X_test)\nY_Pred_Probs = grid_clf_auc.predict_proba(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = grid_clf_auc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross-Validation Score:\n - *sklearn.model_selection.cross_val_score*\n - *Parameters:*\n   - *estimator:* estimator object implementing fit. The object to use to fit the data.\n   - *X:* array-like of shape (n_samples, n_features) The data to fit. Can be for example a list, or an array.\n   - *y:* array-like of shape (n_samples,) or (n_samples, n_outputs), default=None. The target variable to try to predict in the case of supervised learning.\n   - *scoring:* str or callable, default=None (Accuracy). \n     - A str or a scorer callable object / function with signature scorer(estimator, X, y) which should return only a single value, to evaluate the predictions on the test set.\n     - Similar to cross_validate but only a single metric is permitted.\n     - If None, the estimators default scorer (if available) is used.\n   - *cv:* int, cross-validation generator or an iterable, default=None. Determines the cross-validation splitting strategy. Possible inputs for cv are:\n     - *None*: to use the default 5-fold cross validation,\n     - *int*: to specify the number of folds in a (Stratified)KFold.\n - *Returns:*\n   - *scores:* array of float, shape=(len(list(cv)),) Array of scores of the estimator for each run of the cross validation.","metadata":{}},{"cell_type":"code","source":"# accuracy is the default scoring metric\nprint('Cross-validation (accuracy)', cross_val_score(model, X_test, Y_test, cv=5))\n# use AUC as scoring metric\nprint('Cross-validation (AUC)', cross_val_score(model, X_test, Y_test, cv=5, scoring = 'roc_auc'))\n# use precision as scoring metric\nprint('Cross-validation (precision)', cross_val_score(model, X_test, Y_test, cv=5, scoring = 'precision'))\n# use recall as scoring metric\nprint('Cross-validation (recall)', cross_val_score(model, X_test, Y_test, cv=5, scoring = 'recall'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\ndef saveModelJL(model_name, model,path):\n    filename = f\"{path}{model_name}finalized.sav\"\n    joblib.dump(model, filename)\n\ndef loadModelJL(model_name,path):\n    filename = f\"{path}{model_name}finalized.sav\"\n    model = joblib.load(filename)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saveModelJL(model_name,model,base_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = loadModelJL(model_name,base_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}